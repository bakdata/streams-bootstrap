nameOverride: bakdata-streams-app

replicaCount: 1

image: streamsApp
imageTag: latest
imagePullPolicy: Always

imagePullSecrets: []

configurationEnvPrefix: "APP"

# awsRole: my-aws-role

# log4jConfig:

resources:
  requests:
    cpu: 200m
    memory: 300Mi
  limits:
    cpu: 500m
    memory: 2G

streams:
  # brokers: "test:9092"
  # schemaRegistryUrl: "url:1234"
  staticMembership: false
  optimizeLeaveGroupBehavior: true
  passApplicationId: false
  config: {}
  #   max.poll.records: 500
  #   Note that YAML may convert large integers to scientific notation. Use Strings to avoid this.
  #   max.request.size: "1000000"
  inputTopics: []
  # - input
  # - input2
  extraInputTopics: {}
  #   role:
  #     - input
  #     - input2
  # inputPattern: .*-input
  extraInputPatterns: {}
  #   role: .*-input
  # outputTopic: output
  extraOutputTopics: {}
  #   role: output
  # errorTopic: error
  # productive: true

commandLine: {}
#  MY_CLI_PARAM: "foo-bar"

debug: false

env: {}
#  MY_ENV_VARIABLE: foo-bar

secrets: {}
#  MY_SECRET: fo-bar
secretRefs: {}
#  MY_SECRET:
#    name: secretName
#    key: secretKey

# Additional ports
ports: []
#     # Number of the port to expose
#   - containerPort: 8080
#     # Optional: Services can reference port by name
#     name: http
#     # Optional: If not set, kubernetes will use 'TCP'
#     protocol: "TCP"
#    # The port that will be exposed by the service.
#     servicePort: 80

service:
  enabled: false
  labels: {}
  type: "ClusterIP"

# Arbitrary Probe v1 definition: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#probe-v1-core
livenessProbe: {}

# Arbitrary Probe v1 definition: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#probe-v1-core
readinessProbe: {}

## Monitoring
## Kafka Connect JMX Settings
## ref: https://kafka.apache.org/documentation/#connect_monitoring
jmx:
  port: 5555
  metricRules:
    - ".*"

autoscaling:
  enabled: false
  # consumerGroup: foo
  # lagThreshold: "1000"
  pollingInterval: 30
  cooldownPeriod: 300
  offsetResetPolicy: earliest
  minReplicas: 0
  maxReplicas: 1
  # idleReplicas: 0
  ## all topics from streams.inputTopics and streams.extraInputTopics are automatically taken, so
  ## only use the 'topics' option for adding more topics, e.g., internal topics
  topics: []
  #   - bar
  #   - baz
  additionalTriggers: []
#    - type: metrics-api
#      metadata:
#        targetValue: "2"
#        url: "http://custom-metrics-api"
#        valueLocation: "some.json.path"

# serviceAccountName: foo

tolerations: []
#   - key: "foo"
#     operator: "Exists"
#     effect: "NoSchedule"
#   - key: "bar"
#     operator: "Exists"
#     effect: "NoSchedule"

annotations: {}
#  MY_ANNOTATION: "foo-bar"

labels: {}
#  MY_LABEL: "foo-bar"

statefulSet: false

javaOptions:
  maxRAMPercentage: 75
  others: []
#   - "-XX:MinRAMPercentage=50.0"

## Prometheus Exporter Configuration
## ref: https://prometheus.io/docs/instrumenting/exporters/
prometheus:
  ## JMX Exporter Configuration
  ## ref: https://github.com/prometheus/jmx_exporter
  jmx:
    enabled: true
    image: solsson/kafka-prometheus-jmx-exporter@sha256
    imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
    port: 5556

    ## Resources configuration for the JMX exporter container.
    ## See the `resources` documentation above for details.
    resources:
      requests:
        cpu: 100m
        memory: 500Mi
      limits:
        cpu: 300m
        memory: 2G

# priorityClass
# priorityClassName: ""

requirePodAntiAffinity: false

nodeAffinity: {}
#   requiredDuringSchedulingIgnoredDuringExecution:
#     nodeSelectorTerms:
#     - matchExpressions:
#       - key: foo
#         operator: In
#         values:
#         - bar
#         - baz
#   preferredDuringSchedulingIgnoredDuringExecution:
#   - weight: 1
#     preference:
#       matchExpressions:
#       - key: foo
#         operator: In
#         values:
#         - bar
#         - baz

persistence:
  enabled: false

  ## The size of the PersistentVolume to allocate to each streams pod in the StatefulSet.
  size: 1Gi

  ## Kafka Streams data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: ""
